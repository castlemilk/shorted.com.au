{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21994aaf-ebf1-48ed-86d2-97b99813d8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: httpx in /Users/benebsworth/.pyenv/versions/venv/lib/python3.11/site-packages (0.27.0)\n",
      "Requirement already satisfied: tqdm in /Users/benebsworth/.pyenv/versions/venv/lib/python3.11/site-packages (4.66.2)\n",
      "Requirement already satisfied: pandas in /Users/benebsworth/.pyenv/versions/venv/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: chardet in /Users/benebsworth/.pyenv/versions/venv/lib/python3.11/site-packages (5.2.0)\n",
      "Requirement already satisfied: anyio in /Users/benebsworth/.pyenv/versions/venv/lib/python3.11/site-packages (from httpx) (4.3.0)\n",
      "Requirement already satisfied: certifi in /Users/benebsworth/.pyenv/versions/venv/lib/python3.11/site-packages (from httpx) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/benebsworth/.pyenv/versions/venv/lib/python3.11/site-packages (from httpx) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/benebsworth/.pyenv/versions/venv/lib/python3.11/site-packages (from httpx) (3.6)\n",
      "Requirement already satisfied: sniffio in /Users/benebsworth/.pyenv/versions/venv/lib/python3.11/site-packages (from httpx) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/benebsworth/.pyenv/versions/venv/lib/python3.11/site-packages (from httpcore==1.*->httpx) (0.14.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /Users/benebsworth/.pyenv/versions/venv/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/benebsworth/.pyenv/versions/venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/benebsworth/.pyenv/versions/venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/benebsworth/.pyenv/versions/venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/benebsworth/.pyenv/versions/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# retrieving company metadata and exploration\n",
    "!pip install httpx tqdm pandas chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061cc10e-f152-4bd0-8b6c-dc54478b6b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def download_file(client, url, file_path):\n",
    "    \"\"\"Download a file from a given URL to a specified path.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        with client.stream(\"GET\", url) as response:\n",
    "            response.raise_for_status()\n",
    "            with open(file_path, 'wb') as f:\n",
    "                for chunk in response.iter_bytes(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "\n",
    "data_url = 'https://data.gov.au/data/dataset/bc515135-4bb6-4d50-957a-3713709a76d3/resource/55ad4b1c-5eeb-44ea-8b29-d410da431be3/download/business_names_202404.csv'\n",
    "# Initialize an HTTP client\n",
    "client = httpx.Client()\n",
    "file_path = f\"data/{data_url.split('/')[-1]}\"\n",
    "# Fetch the metadata csv:\n",
    "download_file(client, data_url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2509666c-8f44-42e1-95b7-986ee1599193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGISTER_NAME</th>\n",
       "      <th>BN_NAME</th>\n",
       "      <th>BN_STATUS</th>\n",
       "      <th>BN_REG_DT</th>\n",
       "      <th>BN_CANCEL_DT</th>\n",
       "      <th>BN_RENEW_DT</th>\n",
       "      <th>BN_STATE_NUM</th>\n",
       "      <th>BN_STATE_OF_REG</th>\n",
       "      <th>BN_ABN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BUSINESS NAMES</td>\n",
       "      <td>SILENT SCISSORZ</td>\n",
       "      <td>Registered</td>\n",
       "      <td>07/11/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07/11/2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.664328e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BUSINESS NAMES</td>\n",
       "      <td>LITTLE MIRACLES PRESCHOOL &amp; LO...</td>\n",
       "      <td>Registered</td>\n",
       "      <td>27/07/2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27/07/2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.397982e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BUSINESS NAMES</td>\n",
       "      <td>A Cut Above Painting &amp; Texture Coating</td>\n",
       "      <td>Registered</td>\n",
       "      <td>04/12/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/12/2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.663468e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BUSINESS NAMES</td>\n",
       "      <td>HOMSAFE</td>\n",
       "      <td>Registered</td>\n",
       "      <td>07/02/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31/12/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.609895e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BUSINESS NAMES</td>\n",
       "      <td>COASTAL  EARTH WORKS</td>\n",
       "      <td>Registered</td>\n",
       "      <td>30/05/2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30/05/2026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.857312e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072030</th>\n",
       "      <td>BUSINESS NAMES</td>\n",
       "      <td>zzz tyres and auto services</td>\n",
       "      <td>Registered</td>\n",
       "      <td>12/01/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/01/2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.547044e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072031</th>\n",
       "      <td>BUSINESS NAMES</td>\n",
       "      <td>ZZZINKED DIGITAL</td>\n",
       "      <td>Registered</td>\n",
       "      <td>08/04/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/04/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.367605e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072032</th>\n",
       "      <td>BUSINESS NAMES</td>\n",
       "      <td>ZZZY</td>\n",
       "      <td>Registered</td>\n",
       "      <td>27/08/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27/08/2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.656213e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072033</th>\n",
       "      <td>BUSINESS NAMES</td>\n",
       "      <td>ZZZZ BEST TEES</td>\n",
       "      <td>Registered</td>\n",
       "      <td>12/05/2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/05/2026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.866088e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072034</th>\n",
       "      <td>BUSINESS NAMES</td>\n",
       "      <td>Zzzzz Australia</td>\n",
       "      <td>Registered</td>\n",
       "      <td>15/07/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15/07/2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.379036e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3072035 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          REGISTER_NAME                                            BN_NAME  \\\n",
       "0        BUSINESS NAMES                                    SILENT SCISSORZ   \n",
       "1        BUSINESS NAMES                  LITTLE MIRACLES PRESCHOOL & LO...   \n",
       "2        BUSINESS NAMES             A Cut Above Painting & Texture Coating   \n",
       "3        BUSINESS NAMES                                            HOMSAFE   \n",
       "4        BUSINESS NAMES                               COASTAL  EARTH WORKS   \n",
       "...                 ...                                                ...   \n",
       "3072030  BUSINESS NAMES                        zzz tyres and auto services   \n",
       "3072031  BUSINESS NAMES                                   ZZZINKED DIGITAL   \n",
       "3072032  BUSINESS NAMES                                               ZZZY   \n",
       "3072033  BUSINESS NAMES                                     ZZZZ BEST TEES   \n",
       "3072034  BUSINESS NAMES                                    Zzzzz Australia   \n",
       "\n",
       "          BN_STATUS   BN_REG_DT BN_CANCEL_DT BN_RENEW_DT BN_STATE_NUM  \\\n",
       "0        Registered  07/11/2018          NaN  07/11/2025          NaN   \n",
       "1        Registered  27/07/2022          NaN  27/07/2025          NaN   \n",
       "2        Registered  04/12/2019          NaN  04/12/2022          NaN   \n",
       "3        Registered  07/02/2019          NaN  31/12/2024          NaN   \n",
       "4        Registered  30/05/2019          NaN  30/05/2026          NaN   \n",
       "...             ...         ...          ...         ...          ...   \n",
       "3072030  Registered  12/01/2024          NaN  12/01/2025          NaN   \n",
       "3072031  Registered  08/04/2017          NaN  08/04/2024          NaN   \n",
       "3072032  Registered  27/08/2020          NaN  27/08/2023          NaN   \n",
       "3072033  Registered  12/05/2023          NaN  12/05/2026          NaN   \n",
       "3072034  Registered  15/07/2018          NaN  15/07/2025          NaN   \n",
       "\n",
       "        BN_STATE_OF_REG        BN_ABN  \n",
       "0                   NaN  7.664328e+10  \n",
       "1                   NaN  2.397982e+10  \n",
       "2                   NaN  8.663468e+10  \n",
       "3                   NaN  5.609895e+10  \n",
       "4                   NaN  8.857312e+10  \n",
       "...                 ...           ...  \n",
       "3072030             NaN  2.547044e+10  \n",
       "3072031             NaN  8.367605e+10  \n",
       "3072032             NaN  1.656213e+10  \n",
       "3072033             NaN  7.866088e+10  \n",
       "3072034             NaN  6.379036e+10  \n",
       "\n",
       "[3072035 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chardet\n",
    "file_path = f\"data/{data_url.split('/')[-1]}\"\n",
    "with open(file_path, 'rb') as f:\n",
    "    result = chardet.detect(f.read(10000))\n",
    "encoding = result['encoding']\n",
    "df = pd.read_csv(file_path, encoding=encoding, engine='python', sep=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02e13410-a648-4173-954f-bccb4b86f9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dask\n",
      "  Downloading dask-2024.4.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (4.66.2)\n",
      "Collecting requests\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: openai in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (1.16.2)\n",
      "Collecting dask-expr\n",
      "  Downloading dask_expr-1.0.10-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: chardet in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (5.2.0)\n",
      "Requirement already satisfied: pandas in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (2.2.1)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.8.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting click>=8.1 (from dask)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting cloudpickle>=1.5.0 (from dask)\n",
      "  Using cached cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting fsspec>=2021.09.0 (from dask)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (from dask) (24.0)\n",
      "Collecting partd>=1.2.0 (from dask)\n",
      "  Using cached partd-1.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pyyaml>=5.3.1 (from dask)\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting toolz>=0.10.0 (from dask)\n",
      "  Using cached toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting importlib-metadata>=4.13.0 (from dask)\n",
      "  Using cached importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (from requests) (3.6)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (from openai) (2.6.4)\n",
      "Requirement already satisfied: sniffio in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (from openai) (4.11.0)\n",
      "Collecting pyarrow>=7.0.0 (from dask-expr)\n",
      "  Using cached pyarrow-15.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.51.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.5/159.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-10.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=4.13.0->dask)\n",
      "  Using cached zipp-3.18.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting locket (from partd>=1.2.0->dask)\n",
      "  Using cached locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/benebsworth/projects/shorted/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading dask-2024.4.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Downloading dask_expr-1.0.10-py3-none-any.whl (184 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.4/184.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.8.4-cp311-cp311-macosx_11_0_arm64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl (118 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Downloading contourpy-1.2.1-cp311-cp311-macosx_11_0_arm64.whl (245 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.9/245.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.51.0-cp311-cp311-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Using cached importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
      "Using cached kiwisolver-1.4.5-cp311-cp311-macosx_11_0_arm64.whl (66 kB)\n",
      "Using cached partd-1.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading pillow-10.3.0-cp311-cp311-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyarrow-15.0.2-cp311-cp311-macosx_11_0_arm64.whl (24.2 MB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl (167 kB)\n",
      "Using cached toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Using cached zipp-3.18.1-py3-none-any.whl (8.2 kB)\n",
      "Using cached locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: zipp, urllib3, toolz, pyyaml, pyparsing, pyarrow, pillow, locket, kiwisolver, fsspec, fonttools, cycler, contourpy, cloudpickle, click, charset-normalizer, requests, partd, matplotlib, importlib-metadata, dask, dask-expr\n",
      "Successfully installed charset-normalizer-3.3.2 click-8.1.7 cloudpickle-3.0.0 contourpy-1.2.1 cycler-0.12.1 dask-2024.4.1 dask-expr-1.0.10 fonttools-4.51.0 fsspec-2024.3.1 importlib-metadata-7.1.0 kiwisolver-1.4.5 locket-1.0.0 matplotlib-3.8.4 partd-1.4.1 pillow-10.3.0 pyarrow-15.0.2 pyparsing-3.1.2 pyyaml-6.0.1 requests-2.31.0 toolz-0.12.1 urllib3-2.2.1 zipp-3.18.1\n"
     ]
    }
   ],
   "source": [
    "!pip install dask tqdm requests openai dask-expr chardet tqdm pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38dffe62-1050-4bb7-8688-feb9c683e7a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OpenAI' from 'openai' (/opt/homebrew/lib/python3.11/site-packages/openai/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhttpx\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (/opt/homebrew/lib/python3.11/site-packages/openai/__init__.py)"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import json\n",
    "openapi_client = OpenAI(api_key=\"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\")\n",
    "\n",
    "\n",
    "core_messages = [\n",
    "                {\"role\": \"system\", \n",
    "                \"content\": \"\"\"\n",
    "                You are a financial expert, who is able to provide detailed information about companies \n",
    "                listed on the Australian Stock exchange (ASX) in JSON format. You should provide your \n",
    "                response with the following fields/schema:\n",
    "                {\n",
    "                // Name of the ASX company\n",
    "                \"company_name\": string,\n",
    "                // where the company is located/headquartered, the FULL location (i.e stree number, street name, city, state, postcode)\n",
    "                \"address\": string,\n",
    "                // short summary about company\n",
    "                \"summary\": string,\n",
    "                // detailed overview of company profile, innclude industry, history etc.\n",
    "                \"details\": string\n",
    "                // companies website (i.e https://1414degrees.com.au/)\n",
    "                \"website\": string,\n",
    "                // company about or investor page (i.e https://1414degrees.com.au/investors/)\n",
    "                \"website_about\": string,\n",
    "                // link to company logo (i.e https://1414degrees.com.au/wp-content/uploads/2023/04/1414degrees-GreyRed-RGB.png)\n",
    "                \"company_logo_link\": string,\n",
    "                // \"directions and/or senior leadership information\"\n",
    "                \"directors\": [{\"name\": \"links to additional sources of information\"string, \"title\": string}],\n",
    "                // links to additional sources of information\n",
    "                \"references\": [{\"url\": string, \"description\": string}]\n",
    "                }\n",
    "                \"\"\"},\n",
    "            ]\n",
    "\n",
    "def validate_company_metadata(company_metadata_json):\n",
    "    \"\"\"\n",
    "    Validate the company metadata JSON object.\n",
    "    looks at the different fields and the types of the fields and roughly assesses \n",
    "    if the JSON object is valid. If the JSON object is not valid, it will raise an exception. \n",
    "    which can allow follow up queries to be made.\n",
    "    Additionally  does some more advanced checks for urls:\n",
    "     * it will check if the URL is valid and does not return a 404 errors etc\n",
    "     * for images like in the company logo, it will check if the image is valid and can be downloaded\n",
    "    the schema we are checking against is as follows:\n",
    "    {\n",
    "        // Name of the ASX company\n",
    "        \"company_name\": string,\n",
    "        // where the company is located/headquartered, the FULL location (i.e stree number, street name, city, state, postcode)\n",
    "        \"address\": string,\n",
    "        // short summary about company\n",
    "        \"summary\": string,\n",
    "        // detailed overview of company profile, innclude industry, history etc.\n",
    "        \"details\": string\n",
    "        // companies website (i.e https://1414degrees.com.au/)\n",
    "        \"website\": string,\n",
    "        // company about or investor page (i.e https://1414degrees.com.au/investors/)\n",
    "        \"website_about\": string,\n",
    "        // link to company logo (i.e https://1414degrees.com.au/wp-content/uploads/2023/04/1414degrees-GreyRed-RGB.png)\n",
    "        \"company_logo_link\": string,\n",
    "        // \"directions and/or senior leadership information\"\n",
    "        \"directors\": [{\"name\": \"links to additional sources of information\"string, \"title\": string}],\n",
    "        // links to additional sources of information\n",
    "        \"references\": [{\"url\": string, \"description\": string}]\n",
    "    }\n",
    "    \"\"\"\n",
    "    if not isinstance(company_metadata_json, dict):\n",
    "        raise ValueError(\"Company metadata JSON object should be a dictionary\")\n",
    "    if \"company_name\" not in company_metadata_json:\n",
    "        raise ValueError(\"Company metadata JSON object should have a 'company_name' field\")\n",
    "    if not isinstance(company_metadata_json[\"company_name\"], str):\n",
    "        raise ValueError(\"Company metadata JSON object 'company_name' field should be a string\")\n",
    "    if \"address\" not in company_metadata_json:\n",
    "        raise ValueError(\"Company metadata JSON object should have a 'address' field\")\n",
    "    if not isinstance(company_metadata_json[\"address\"], str):\n",
    "        raise ValueError(\"Company metadata JSON object 'address' field should be a string\")\n",
    "    if \"summary\" not in company_metadata_json:\n",
    "        raise ValueError(\"Company metadata JSON object should have a 'summary' field\")\n",
    "    if not isinstance(company_metadata_json[\"summary\"], str):\n",
    "        raise ValueError(\"Company metadata JSON object 'summary' field should be a string\")\n",
    "    if \"details\" not in company_metadata_json:\n",
    "        raise ValueError(\"Company metadata JSON object should have a 'details' field\")\n",
    "    if not isinstance(company_metadata_json[\"details\"], str):\n",
    "        raise ValueError(\"Company metadata JSON object 'details' field should be a string\")\n",
    "    if \"website\" not in company_metadata_json:\n",
    "        raise ValueError(\"Company metadata JSON object should have a 'website' field\")\n",
    "    if not isinstance(company_metadata_json[\"website\"], str):\n",
    "        raise ValueError(\"Company metadata JSON object 'website' field should be a string\")\n",
    "    if \"website_about\" not in company_metadata_json:\n",
    "        raise ValueError(\"Company metadata JSON object should have a 'website_about' field\")\n",
    "    if not isinstance(company_metadata_json[\"website_about\"], str):\n",
    "        raise ValueError(\"Company metadata JSON object 'website_about' field should be a string\")\n",
    "    if \"company_logo_link\" not in company_metadata_json:\n",
    "        raise ValueError(\"Company metadata JSON object should have a 'company_logo_link' field\")\n",
    "    if not isinstance(company_metadata_json[\"company_logo_link\"], str):\n",
    "        raise ValueError(\"Company metadata JSON object 'company_logo_link' field should be a string\")\n",
    "    if \"directors\" not in company_metadata_json:\n",
    "        raise ValueError(\"Company metadata JSON object should have a 'directors' field\")\n",
    "    if not isinstance(company_metadata_json[\"directors\"], list):\n",
    "        raise ValueError(\"Company metadata JSON object 'directors' field should be a list\")\n",
    "    for director in company_metadata_json[\"directors\"]:\n",
    "        if not isinstance(director, dict):\n",
    "            raise ValueError(\"Company metadata JSON object 'directors' field should be a list of dictionaries\")\n",
    "        if \"name\" not in director:\n",
    "            raise ValueError(\"Company metadata JSON object 'directors' field should have a 'name' field\")\n",
    "        if not isinstance(director[\"name\"], str):\n",
    "            raise ValueError(\"Company metadata JSON object 'directors' field 'name' field should be a string\")\n",
    "        if \"title\" not in director:\n",
    "            raise ValueError(\"Company metadata JSON object 'directors' field should have a 'title' field\")\n",
    "        if not isinstance(director[\"title\"], str):\n",
    "            raise ValueError(\"Company metadata JSON object 'directors' field 'title' field should be a string\")\n",
    "    if \"references\" not in company_metadata_json:\n",
    "        raise ValueError(\"Company metadata JSON object should have a 'references' field\")\n",
    "    if not isinstance(company_metadata_json[\"references\"], list):\n",
    "        raise ValueError(\"Company metadata JSON object 'references' field should be a list\")\n",
    "    for reference in company_metadata_json[\"references\"]:\n",
    "        if not isinstance(reference, dict):\n",
    "            raise ValueError(\"Company metadata JSON object 'references' field should be a list of dictionaries\")\n",
    "        if \"url\" not in reference:\n",
    "            raise ValueError(\"Company metadata JSON object 'references' field should have a 'url' field\")\n",
    "        if not isinstance(reference[\"url\"], str):\n",
    "            raise ValueError(\"Company metadata JSON object 'references' field 'url' field should be a string\")\n",
    "        if \"description\" not in reference:\n",
    "            raise ValueError(\"Company metadata JSON object 'references' field should have a 'description' field\")\n",
    "        if not isinstance(reference[\"description\"], str):\n",
    "            raise ValueError(\"Company metadata JSON object 'references' field 'description' field should be a string\")\n",
    "    # check if the urls are valid\n",
    "    for reference in company_metadata_json[\"references\"]:\n",
    "        try:\n",
    "            response = httpx.get(reference[\"url\"])\n",
    "            if [response.status_code] in [200,301, 302, 303, 304]:\n",
    "                company_metadata_json[\"references\"].remove(reference)\n",
    "        except Exception as e:\n",
    "            company_metadata_json[\"references\"].remove(reference)\n",
    "        \n",
    "            # TODO: do some error handling and try find alternative references\n",
    "            # raise ValueError(f\"URL {reference['url']} is not valid, got status: {response.status_code}, response: {response.text}\")\n",
    "    try:\n",
    "        response = httpx.get(company_metadata_json[\"website\"])\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"URL {company_metadata_json['website']} is likely an invalid format, must contain `http://` or `https://`, got error: {str(e)}\")\n",
    "    \n",
    "    if [response.status_code] in [200, 301, 302, 303, 304]:\n",
    "        raise ValueError(f\"URL {company_metadata_json['website']} is not valid, got status: {response.status_code}, response: {response.text}\")\n",
    "    \n",
    "    try:\n",
    "        response = httpx.get(company_metadata_json[\"website_about\"])\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"URL {company_metadata_json['website']} is likely an invalid format or failed to connect, must contain `http://` or `https://`\")\n",
    "    if [response.status_code] in [200, 301,  302, 303, 304]:\n",
    "        raise ValueError(f\"URL {company_metadata_json['website_about']} is not valid, got status: {response.status_code}, response: {response.text}\")\n",
    "    try:\n",
    "        response = httpx.get(company_metadata_json[\"company_logo_link\"])\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"URL {company_metadata_json['website']} is likely an invalid format, must contain `http://` or `https://`\")\n",
    "    if [response.status_code] in [200, 301, 302, 303, 304]:\n",
    "        raise ValueError(f\"URL {company_metadata_json['company_logo_link']} is not valid, got status: {response.status_code}, response: {response.text}\")\n",
    "    # check the logo is an image\n",
    "    if not response.headers['Content-Type'].startswith('image'):\n",
    "        raise ValueError(f\"URL {company_metadata_json['company_logo_link']} is not an image\")\n",
    "    # check the logo is of a specific format (png, jpg, jpeg, svg)\n",
    "    if not response.headers['Content-Type'].endswith(('png', 'jpg', 'jpeg')):\n",
    "        raise ValueError(f\"URL {company_metadata_json['company_logo_link']} is not a valid image format\")\n",
    "def get_company_metadata(stock_code):\n",
    "    attempts = 5  # Initialize attempt count\n",
    "    while attempts > 0:\n",
    "        try:\n",
    "            response = openapi_client.chat.completions.create(\n",
    "                model='gpt-3.5-turbo-0125',\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                messages=core_messages + [{\"role\": \"user\", \"content\": f\"give me information on the ASX company with stock code {stock_code}\"}]\n",
    "            )\n",
    "            company_metadata_json = json.loads(response.choices[0].message.content)\n",
    "            validate_company_metadata(company_metadata_json)\n",
    "        except json.JSONDecodeError as e:\n",
    "            # Error handling specifically for JSON decoding errors\n",
    "            print(f\"JSON decode error on attempt {8 - attempts}: {str(e)}\")\n",
    "            # Update the retry message for specific errors\n",
    "            core_messages.append({\"role\": \"user\", \"content\": f\"the JSON object provided is not valid, please provide a valid JSON object. Here is the error message: {str(e)}\"})\n",
    "            attempts -= 1\n",
    "            # Missing the decrement for attempts here, also this block might not reset attempts correctly\n",
    "        except ValueError as e:\n",
    "            # Error handling for validation failures\n",
    "            if \"URL\" in str(e) and \"is not valid\" in str(e):\n",
    "                # Fetching page content should be within try-except block\n",
    "                try:\n",
    "                    page_content = ' '.join(httpx.get(company_metadata_json['website']).text.split(\" \")[:400])\n",
    "                    msg = {\"role\": \"user\", \"content\": f\"an error was seen in one of the URLs: {str(e)} is and/or is not valid, please provide a valid URL. Here is the content of the company website: {page_content}, use this to potentially find a more valid URL\"}\n",
    "                    if not any([page_content in m.get(\"content\", \"\") for m in core_messages]):\n",
    "                        core_messages.append(msg)\n",
    "                except Exception as httpx_error:\n",
    "                    print(f\"HTTPX error when fetching page content: {httpx_error}\")\n",
    "                    core_messages.append({\"role\": \"user\", \"content\": f\"couldn't use the company website link provided to get additional metadata, please ensure this link is correct. Here is the error message: {str(httpx_error)}\"})\n",
    "            elif \"is not an image\" in str(e):\n",
    "                 # Fetching page content should be within try-except block\n",
    "                try:\n",
    "                    page_content = ' '.join(httpx.get(company_metadata_json['website']).text.split(\" \")[:400])\n",
    "                    msg = {\"role\": \"user\", \"content\": f\"an error was seen in one of the URLs: {str(e)} is and/or is not valid, please provide a valid URL. Here is the content of the company website: {page_content}, use this to potentially find a more valid URL for the image\"}\n",
    "                    if not any([page_content in m.get(\"content\", \"\") for m in core_messages]):\n",
    "                        core_messages.append(msg)\n",
    "                except Exception as httpx_error:\n",
    "                    print(f\"HTTPX error when fetching page content: {httpx_error}\")\n",
    "                    core_messages.append({\"role\": \"user\", \"content\": f\"couldn't use the company website link provided to get additional metadata, please ensure this link is correct. Here is the error message: {str(httpx_error)}\"})\n",
    "            core_messages.append({\"role\": \"user\", \"content\": f\"the JSON object provided is not valid according to the provided schema, please ensure the structure is correct as per the schema. Here is the error message: {str(e)}\"})\n",
    "            attempts -= 1\n",
    "            print(f\"Validation error on attempt {8 - attempts}: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            # For unexpected errors, decrementing attempts and logging the attempt\n",
    "            print(f\"Unexpected error on attempt {8 - attempts}: {str(e)}, {e}\")\n",
    "            attempts -= 1\n",
    "            continue  # Continue to the next iteration if it's not the final attempt\n",
    "\n",
    "            # Common processing after successful response\n",
    "        try:\n",
    "            df = pd.json_normalize(company_metadata_json)\n",
    "            df['stock_code'] = stock_code\n",
    "            df.index = [stock_code]\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Error normalizing JSON to DataFrame: {str(e)}\")\n",
    "            core_messages.append({\"role\": \"user\", \"content\": f\"failed to normalize JSON object to DataFrame, likely malformed json, please ensure the structure is correct as per the schema\"})\n",
    "            attempts -= 1\n",
    "\n",
    "    # After all attempts\n",
    "    response = openapi_client.chat.completions.create(\n",
    "                model='gpt-4-0125-preview',\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                messages=core_messages + [{\"role\": \"user\", \"content\": f\"give me information on the ASX company with stock code {stock_code}\"}]\n",
    "            )\n",
    "    company_metadata_json = json.loads(response.choices[0].message.content)\n",
    "    df = pd.json_normalize(company_metadata_json)\n",
    "    df['stock_code'] = stock_code\n",
    "    df.index = [stock_code]\n",
    "    return df\n",
    "    # raise Exception(f\"Failed to retrieve and process company metadata after 8 attempts. stock: {stock_code} messages: {core_messages}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "debb281e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>address</th>\n",
       "      <th>summary</th>\n",
       "      <th>details</th>\n",
       "      <th>website</th>\n",
       "      <th>website_about</th>\n",
       "      <th>company_logo_link</th>\n",
       "      <th>directors</th>\n",
       "      <th>references</th>\n",
       "      <th>stock_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14D</th>\n",
       "      <td>1414 Degrees Limited</td>\n",
       "      <td>25 North Terrace, Adelaide, South Australia, 5000</td>\n",
       "      <td>1414 Degrees is a developer of sustainable, cl...</td>\n",
       "      <td>1414 Degrees operates in the energy storage in...</td>\n",
       "      <td>https://1414degrees.com.au/</td>\n",
       "      <td>https://1414degrees.com.au/investors/</td>\n",
       "      <td>https://1414degrees.com.au/wp-content/uploads/...</td>\n",
       "      <td>[{'name': 'Jim Caddy', 'title': 'Chairman'}, {...</td>\n",
       "      <td>[{'url': 'https://www.asx.com.au/asx/share-pri...</td>\n",
       "      <td>14D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             company_name                                            address  \\\n",
       "14D  1414 Degrees Limited  25 North Terrace, Adelaide, South Australia, 5000   \n",
       "\n",
       "                                               summary  \\\n",
       "14D  1414 Degrees is a developer of sustainable, cl...   \n",
       "\n",
       "                                               details  \\\n",
       "14D  1414 Degrees operates in the energy storage in...   \n",
       "\n",
       "                         website                          website_about  \\\n",
       "14D  https://1414degrees.com.au/  https://1414degrees.com.au/investors/   \n",
       "\n",
       "                                     company_logo_link  \\\n",
       "14D  https://1414degrees.com.au/wp-content/uploads/...   \n",
       "\n",
       "                                             directors  \\\n",
       "14D  [{'name': 'Jim Caddy', 'title': 'Chairman'}, {...   \n",
       "\n",
       "                                            references stock_code  \n",
       "14D  [{'url': 'https://www.asx.com.au/asx/share-pri...        14D  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "res = get_company_metadata('14D')\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e63ab185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##                                      ] | 5% Completed | 17m 56sss\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m ddf \u001b[38;5;241m=\u001b[39m dd\u001b[38;5;241m.\u001b[39mfrom_delayed(delayed_results)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ProgressBar():\n\u001b[0;32m---> 23\u001b[0m     agg_df \u001b[38;5;241m=\u001b[39m \u001b[43mddf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     ddf\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m     26\u001b[0m agg_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/projects/shorted/venv/lib/python3.11/site-packages/dask_expr/_collection.py:453\u001b[0m, in \u001b[0;36mFrameBase.compute\u001b[0;34m(self, fuse, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mrepartition(npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    452\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39moptimize(fuse\u001b[38;5;241m=\u001b[39mfuse)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDaskMethodsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/shorted/venv/lib/python3.11/site-packages/dask/base.py:375\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    352\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/projects/shorted/venv/lib/python3.11/site-packages/dask/base.py:661\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 661\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.8/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# download asx directory from asx\n",
    "# from: https://www.asx.com.au/markets/trade-our-cash-market/directory\n",
    "import time\n",
    "asx_company_url = 'https://asx.api.markitdigital.com/asx-research/1.0/companies/directory/file?access_token=83ff96335c2d45a094df02a206a39ff4'\n",
    "company_list_path = f\"data/ASX_Listed_Companies_07-04-2024_11-03-45_AEST.csv\"\n",
    "download_file(client, data_url, company_list_path)\n",
    "import chardet\n",
    "with open(company_list_path, 'rb') as f:\n",
    "    result = chardet.detect(f.read(10000))\n",
    "encoding = result['encoding']\n",
    "df_company_list = pd.read_csv(company_list_path, encoding=encoding, engine='python', sep=None)\n",
    "df_company_list\n",
    "\n",
    "# iterate through the stocks and get the metadata from the openAI query. Parallelise this using dask\n",
    "stocks = df_company_list['ASX code'].tolist()\n",
    "\n",
    "delayed_results = [dask.delayed(get_company_metadata)(stock) for stock in stocks]\n",
    "\n",
    "ddf = dd.from_delayed(delayed_results)\n",
    "\n",
    "\n",
    "with ProgressBar():\n",
    "    agg_df = ddf.compute()\n",
    "    ddf.result()\n",
    "\n",
    "agg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1659a6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.1414degrees.com.au/wp-content/uploads/2023/04/1414degrees-GreyRed-RGB.png'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_df.iloc[10].company_logo_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcf08e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# refactor code into a resolver pattern, where each field of the schema has its own \"resolver\". \n",
    "# Each resolver can then have a more specific context provided and appropriate error handling, as well as fallback/default behaviour. \n",
    "# Some advantages this will provide:\n",
    "# * after x attempts to resolve a field, we can provide a default value\n",
    "# * we can provide more specific error handling for each field\n",
    "# * we can provide more specific context for each field\n",
    "# * we can provide more specific error messages for each field and typing\n",
    "# * we can provide more specific error messages for each field and validation\n",
    "# * we could enhance the parallelisation of the data discovery as we could break up work across different resolvers, however would likely translate to even more queries and cost etc.\n",
    "# * resolvers would be entirely domain/context specific workflows and hence can be customised and extended as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
