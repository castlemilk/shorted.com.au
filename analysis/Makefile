.PHONY: help install download populate populate-skip-download append dry-run clean verify

# Default database URL for local development
# Note: Local docker-compose uses admin/password on port 5438
DATABASE_URL ?= postgresql://admin:password@localhost:5438/shorts

# Default target
help:
	@echo "üìä Short Position Data Population"
	@echo ""
	@echo "Available commands:"
	@echo "  make install                 - Install Python dependencies"
	@echo "  make download                - Download CSV files from ASIC (10-20 min)"
	@echo "  make populate                - Download + process + load to DB (30-60 min)"
	@echo "  make populate-skip-download  - Process existing CSVs + load to DB (15-20 min)"
	@echo "  make append                  - Append new data to existing table"
	@echo "  make dry-run                 - Test processing without writing to DB"
	@echo "  make verify                  - Verify data in database"
	@echo "  make clean                   - Remove downloaded CSV files"
	@echo ""
	@echo "Database:"
	@echo "  Defaults to: postgresql://postgres:postgres@localhost:5432/postgres"
	@echo "  Override with: export DATABASE_URL='postgresql://...'"
	@echo ""
	@echo "Example usage:"
	@echo "  make install"
	@echo "  make populate-skip-download"
	@echo ""
	@echo "  # Or with custom database:"
	@echo "  export DATABASE_URL='postgresql://user:pass@host:5432/db'"
	@echo "  make populate-skip-download"

# Install Python dependencies
install:
	@echo "üì¶ Installing Python dependencies..."
	pip install -r requirements.txt
	@echo "‚úÖ Dependencies installed"

# Download CSV files from ASIC
download:
	@echo "üì• Downloading short position data from ASIC..."
	@echo "‚ö†Ô∏è  This will download ~3,500 CSV files (~1GB)"
	@echo "‚è±Ô∏è  Estimated time: 10-20 minutes"
	@echo ""
	@read -p "Continue? [y/N] " -n 1 -r; \
	echo; \
	if [[ $$REPLY =~ ^[Yy]$$ ]]; then \
		cd ../scripts && npm install && npx ts-node sync-short-data.ts; \
	else \
		echo "‚ùå Cancelled"; \
		exit 1; \
	fi

# Full population: download + process + load
populate:
	@echo "üöÄ Full population: download + process + load"
	@echo "üìä Database: $(DATABASE_URL)"
	@echo "‚è±Ô∏è  Estimated time: 30-60 minutes"
	@echo ""
	DATABASE_URL=$(DATABASE_URL) python3 populate_shorts_from_csv.py

# Process existing CSVs and load to database
populate-skip-download:
	@echo "üöÄ Processing existing CSV files and loading to database..."
	@echo "üìä Database: $(DATABASE_URL)"
	@echo "‚è±Ô∏è  Estimated time: 15-20 minutes"
	@echo ""
	DATABASE_URL=$(DATABASE_URL) python3 populate_shorts_from_csv.py --skip-download

# Append new data to existing table
append:
	@echo "‚ûï Appending new data to existing shorts table..."
	@echo "üìä Database: $(DATABASE_URL)"
	DATABASE_URL=$(DATABASE_URL) python3 populate_shorts_from_csv.py --skip-download --append

# Dry run - process but don't write to database
dry-run:
	@echo "üß™ Dry run - processing data without database write..."
	python3 populate_shorts_from_csv.py --skip-download --dry-run

# Verify data in database
verify:
	@echo "‚úÖ Verifying shorts data in database..."
	@echo "üìä Database: $(DATABASE_URL)"
	@echo ""
	@echo "üìä Record counts:"
	@psql "$(DATABASE_URL)" -c "SELECT COUNT(*) as total_records FROM shorts;"
	@echo ""
	@echo "üìä Unique stocks:"
	@psql "$(DATABASE_URL)" -c "SELECT COUNT(DISTINCT \"PRODUCT_CODE\") as unique_stocks FROM shorts;"
	@echo ""
	@echo "üìÖ Date range:"
	@psql "$(DATABASE_URL)" -c "SELECT MIN(\"DATE\")::date as earliest, MAX(\"DATE\")::date as latest FROM shorts;"
	@echo ""
	@echo "üìà Top 10 stocks by record count:"
	@psql "$(DATABASE_URL)" -c "SELECT \"PRODUCT_CODE\", COUNT(*) as records FROM shorts GROUP BY \"PRODUCT_CODE\" ORDER BY records DESC LIMIT 10;"

# Clean downloaded CSV files
clean:
	@echo "üßπ Cleaning downloaded CSV files..."
	@if [ -d "data/shorts" ]; then \
		rm -rf data/shorts/*.csv; \
		echo "‚úÖ Cleaned $(shell ls -1 data/shorts/*.csv 2>/dev/null | wc -l) CSV files"; \
	else \
		echo "‚úÖ No CSV files to clean"; \
	fi

# Quick start with sample data (no download required)
sample:
	@echo "üöÄ Loading sample data (CBA, BHP, RMD, RMX)..."
	@echo "üìä Database: $(DATABASE_URL)"
	@psql "$(DATABASE_URL)" -f sql/init-db.sql
	@echo "‚úÖ Sample data loaded"

# Check if CSV files exist
check-csvs:
	@echo "üìÅ Checking for CSV files..."
	@if [ -d "data/shorts" ]; then \
		count=$$(ls -1 data/shorts/*.csv 2>/dev/null | wc -l | tr -d ' '); \
		if [ "$$count" -gt 0 ]; then \
			echo "‚úÖ Found $$count CSV files in data/shorts/"; \
			size=$$(du -sh data/shorts 2>/dev/null | cut -f1); \
			echo "üì¶ Total size: $$size"; \
		else \
			echo "‚ö†Ô∏è  No CSV files found in data/shorts/"; \
			echo "   Run 'make download' to fetch them"; \
		fi; \
	else \
		echo "‚ö†Ô∏è  Directory data/shorts/ does not exist"; \
		echo "   Run 'make download' to create it and fetch CSV files"; \
	fi

# Show status of everything
status:
	@echo "üìä SHORT POSITION DATA STATUS"
	@echo "========================================"
	@echo ""
	@echo "1Ô∏è‚É£  Python Dependencies:"
	@if python3 -c "import httpx, tqdm, pandas, dask, chardet, sqlalchemy, psycopg2" 2>/dev/null; then \
		echo "   ‚úÖ All dependencies installed"; \
	else \
		echo "   ‚ùå Missing dependencies (run 'make install')"; \
	fi
	@echo ""
	@echo "2Ô∏è‚É£  CSV Files:"
	@if [ -d "data/shorts" ]; then \
		count=$$(ls -1 data/shorts/*.csv 2>/dev/null | wc -l | tr -d ' '); \
		if [ "$$count" -gt 0 ]; then \
			echo "   ‚úÖ Found $$count CSV files"; \
		else \
			echo "   ‚ö†Ô∏è  No CSV files (run 'make download')"; \
		fi; \
	else \
		echo "   ‚ö†Ô∏è  No CSV files (run 'make download')"; \
	fi
	@echo ""
	@echo "3Ô∏è‚É£  Database:"
	@echo "   üìä URL: $(DATABASE_URL)"
	@if psql "$(DATABASE_URL)" -c "SELECT 1 FROM shorts LIMIT 1" >/dev/null 2>&1; then \
		count=$$(psql "$(DATABASE_URL)" -tAc "SELECT COUNT(*) FROM shorts"); \
		echo "   ‚úÖ Connected - $$count records in shorts table"; \
	else \
		echo "   ‚ö†Ô∏è  Cannot query shorts table (may be empty or not connected)"; \
	fi
	@echo ""
	@echo "========================================"
	@echo "Run 'make help' for available commands"

