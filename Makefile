# Shorted.com.au Root Makefile
# Orchestrates testing and building for both frontend and backend

.PHONY: help run test test-frontend test-backend test-coverage test-watch test-integration test-e2e test-e2e-ui test-e2e-headed test-stack-up test-stack-down install install-hooks clean clean-cache clean-all clean-ports build dev dev-clean dev-script dev-frontend dev-backend lint format populate-data populate-data-quick db-diagnose db-optimize db-analyze algolia-sync algolia-sync-prod algolia-search enrich-metadata enrich-metadata-all enrich-metadata-stocks pipeline-local pipeline-prod pipeline-daily pipeline-help

# Default target
help:
	@echo "Available commands:"
	@echo "  run              - Start all services for local development (alias for dev)"
	@echo "  dev              - Start database, backend and frontend dev servers"
	@echo "  dev-db           - Start PostgreSQL database only"
	@echo "  dev-frontend     - Start frontend dev server only"
	@echo "  dev-backend      - Start backend dev server only (shorts service)"
	@echo "  dev-market-data  - Start market data service only (port 8090)"
	@echo "  dev-stop         - Stop all development services"
	@echo "  install       - Install all dependencies"
	@echo "  install-hooks - Install git hooks for pre-commit testing"
	@echo "  clean         - Clean all build artifacts"
	@echo "  clean-cache   - Clear Next.js caches (fixes 'Element type is invalid' errors)"
	@echo "  clean-all     - Clean build artifacts AND caches"
	@echo "  clean-ports   - Kill any stale processes on development ports (9091, 3000, 5432)"
	@echo "  build         - Build frontend and backend"
	@echo "  test          - Run complete pre-push validation (lint + build + unit + integration)"
	@echo "  test-unit     - Run unit tests only (frontend + backend)"
	@echo "  test-frontend - Run frontend tests only"
	@echo "  test-backend  - Run backend tests only"
	@echo "  test-coverage - Run all tests with coverage reporting"
	@echo "  test-watch    - Run frontend tests in watch mode"
	@echo "  test-integration-local - Run integration tests with local backend (self-contained)"
	@echo "  test-integration - Run full-stack integration tests"
	@echo "  test-e2e      - Run E2E tests with all dependencies"
	@echo "  test-e2e-ui   - Run E2E tests in Playwright UI mode"
	@echo "  test-stack-up - Start test environment"
	@echo "  test-stack-down - Stop test environment"
	@echo "  lint          - Run linting (TypeScript + golangci-lint)"
	@echo "  lint-frontend - Run TypeScript/ESLint linting"
	@echo "  lint-backend  - Run golangci-lint for Go code"
	@echo "  format        - Format code for all projects"
	@echo "  populate-data - Download and populate database with ASIC short selling data"
	@echo "  populate-data-quick - Populate database using existing CSV files (no download)"
	@echo "  db-diagnose   - Diagnose database query performance issues"
	@echo "  db-optimize   - Apply performance indexes to database"
	@echo "  db-analyze    - Update database statistics for query optimizer"

# Test commands
test: lint build-frontend test-unit
	@if docker info > /dev/null 2>&1; then \
		echo "üê≥ Docker available - running integration tests..."; \
		$(MAKE) test-integration-local; \
		echo ""; \
		echo "‚úÖ All tests, linting, and build validation completed successfully!"; \
		echo "   üîç Linting: TypeScript + Go"; \
		echo "   üèóÔ∏è  Build: Frontend (type checking)"; \
		echo "   üß™ Unit Tests: Frontend + Backend"; \
		echo "   üîó Integration Tests: Backend"; \
	else \
		echo ""; \
		echo "‚ö†Ô∏è  Docker not available - skipping integration tests"; \
		echo "   Start Docker Desktop to run integration tests"; \
		echo ""; \
		echo "‚úÖ Lint, build, and unit tests completed successfully!"; \
		echo "   üîç Linting: TypeScript + Go"; \
		echo "   üèóÔ∏è  Build: Frontend (type checking)"; \
		echo "   üß™ Unit Tests: Frontend + Backend"; \
	fi
	@echo ""

# Unit tests only (no linting, no integration)
test-unit: test-frontend test-backend

test-frontend:
	@echo "üß™ Running frontend tests..."
	@cd web && npm test -- --watchAll=false --testPathIgnorePatterns=integration

test-backend:
	@echo "üß™ Running backend tests..."
	@cd services && make test

test-coverage: test-frontend-coverage test-backend-coverage

test-frontend-coverage:
	@echo "üìä Running frontend tests with coverage..."
	@cd web && npm run test:coverage

test-backend-coverage:
	@echo "üìä Running backend tests with coverage..."
	@cd services && make test.coverage

test-watch:
	@echo "üëÄ Running frontend tests in watch mode..."
	@cd web && npm run test:watch

# Installation commands
install: install-frontend install-backend

install-frontend:
	@echo "üì¶ Installing frontend dependencies..."
	@cd web && npm install

install-backend:
	@echo "üì¶ Installing backend dependencies..."
	@cd services && go mod download && go mod tidy

install-hooks: ## Install git hooks for pre-commit testing
	@echo "üîß Installing git hooks..."
	@bash scripts/install-hooks.sh

# Clean commands
clean: clean-frontend clean-backend

clean-frontend:
	@echo "üßπ Cleaning frontend build artifacts..."
	@cd web && rm -rf .next out coverage/

clean-backend:
	@echo "üßπ Cleaning backend build artifacts..."
	@cd services && go clean -cache -testcache && rm -f coverage.out coverage.html

clean-cache: ## Clear Next.js and webpack caches (fixes "Element type is invalid" errors)
	@echo "üßπ Clearing Next.js and webpack caches..."
	@cd web && rm -rf .next node_modules/.cache
	@echo "‚úÖ Caches cleared - restart dev server with 'make dev'"

clean-all: clean clean-cache ## Clean all build artifacts and caches
	@echo "‚úÖ All build artifacts and caches cleared"

clean-ports:
	@echo "üßπ Killing stale processes on development ports..."
	@-lsof -ti :9091 | xargs kill -9 2>/dev/null || true
	@-lsof -ti :3000 | xargs kill -9 2>/dev/null || true
	@-lsof -ti :8090 | xargs kill -9 2>/dev/null || true
	@echo "‚úÖ Ports cleaned (9091, 3000, 8090)"

# Build commands
build: build-frontend

build-frontend:
	@echo "üèóÔ∏è  Building frontend..."
	@cd web && npm run build

build-backend:
	@echo "üèóÔ∏è  Building backend..."
	@cd services && make build.shorts

# Development commands
run: dev ## Start all services for local development (alias for dev)

dev: dev-stop-services dev-db ## Start database, backend and frontend development servers
	@if [ -f package.json ] && command -v npm >/dev/null 2>&1; then \
		echo "üöÄ Starting full application with npm concurrently..."; \
		npm run dev; \
	else \
		echo "üöÄ Starting full application..."; \
		echo "Frontend: http://localhost:3020"; \
		echo "Backend: http://localhost:9091"; \
		echo "Database: localhost:5438"; \
		echo ""; \
		echo "Press Ctrl+C to stop all services"; \
		echo "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"; \
		make -j 2 dev-frontend dev-backend; \
	fi

dev-db: ## Start the PostgreSQL database for development
	@echo "üóÑÔ∏è  Starting PostgreSQL database..."
	@cd analysis/sql && docker compose up -d postgres
	@echo "‚è≥ Waiting for database to be ready..."
	@for i in 1 2 3 4 5 6 7 8 9 10; do \
		if docker exec shorted_db pg_isready -U admin -d shorts > /dev/null 2>&1; then \
			echo "‚úÖ Database is ready"; \
			exit 0; \
		fi; \
		echo "Attempt $$i/10: Database not ready yet, waiting..."; \
		sleep 3; \
	done; \
	echo "‚ö†Ô∏è  Database may not be ready after 30 seconds"; \
	exit 1;

dev-script: ## Start development using the shell script
	@./scripts/dev.sh

dev-frontend:
	@echo "üöÄ Starting frontend development server..."
	@cd web && npm run dev

dev-backend:
	@echo "üöÄ Starting backend development server..."
	@cd services && make run.shorts

dev-market-data:
	@echo "üöÄ Starting market data service..."
	@cd services && make run.market-data

dev-stop-services: ## Stop only application services (not database)
	@echo "üõë Stopping application services..."
	@echo "Stopping frontend service on port 3020..."
	@lsof -ti:3020 | xargs kill -9 2>/dev/null || true
	@echo "Stopping backend service on port 9091..."
	@lsof -ti:9091 | xargs kill -9 2>/dev/null || true
	@echo "Stopping market data service on port 8090..."
	@lsof -ti:8090 | xargs kill -9 2>/dev/null || true
	@echo "‚úÖ Application services stopped"

dev-stop: ## Stop all development services
	@echo "üõë Stopping all development services..."
	@cd analysis/sql && docker compose down
	@make dev-stop-services

populate-data: dev-db ## Download and populate database with ASIC short selling data
	@echo "üìä Populating database with short selling data..."
	@cd services && make populate-data

populate-data-quick: dev-db ## Populate database using existing CSV files (no download)
	@echo "üìä Quick populating database from existing files..."
	@cd services && make populate-data-quick

populate-stock-data: dev-db ## Populate database with historical stock price data
	@echo "üìä Populating database with historical stock price data..."
	@cd services/stock-price-ingestion && python populate_historical_data.py

populate-stock-data-full: dev-db ## Populate database with full historical stock data (5 years)
	@echo "üìä Populating database with 5 years of stock price data..."
	@cd services/stock-price-ingestion && python populate_historical_data.py --start-date $$(date -d "5 years ago" +%Y-%m-%d)

populate-stock-data-custom: dev-db ## Populate with custom stocks and date range
	@echo "üìä Usage: make populate-stock-data-custom STOCKS=CBA,BHP,CSL START=2022-01-01 END=2024-01-01"
	@cd services/stock-price-ingestion && python populate_historical_data.py --stocks $(STOCKS) --start-date $(START) --end-date $(END)

repair-gaps: dev-db ## Detect and repair historical data gaps (usage: make repair-gaps STOCKS=CBA,BHP)
	@echo "üõ†Ô∏è Repairing historical data gaps..."
	@if [ -z "$$DATABASE_URL" ]; then \
		export DATABASE_URL="postgresql://admin:password@localhost:5438/shorts"; \
	fi; \
	if [ -n "$(STOCKS)" ]; then \
		python3 scripts/repair-gaps.py --stocks $(STOCKS); \
	else \
		python3 scripts/repair-gaps.py; \
	fi

repair-gaps-all: dev-db ## Batch repair ALL stocks with insufficient data (< 2000 records)
	@echo "üõ†Ô∏è Starting batch repair of all stocks with gaps..."
	@if [ -z "$$DATABASE_URL" ]; then \
		export DATABASE_URL="postgresql://admin:password@localhost:5438/shorts"; \
	fi; \
	python3 scripts/repair-gaps.py --repair-all $(if $(LIMIT),--limit $(LIMIT),) $(if $(DRY_RUN),--dry-run,)

repair-gaps-dry-run: dev-db ## Show which stocks would be repaired (no changes made)
	@echo "üîç Checking which stocks need repair..."
	@if [ -z "$$DATABASE_URL" ]; then \
		export DATABASE_URL="postgresql://admin:password@localhost:5438/shorts"; \
	fi; \
	python3 scripts/repair-gaps.py --repair-all --dry-run

repair-gaps-status: dev-db ## Show repair status summary
	@echo "üìä Checking historical data status..."
	@if [ -z "$$DATABASE_URL" ]; then \
		export DATABASE_URL="postgresql://admin:password@localhost:5438/shorts"; \
	fi; \
	psql $$DATABASE_URL -c " \
		SELECT \
			COUNT(*) as total_stocks, \
			COUNT(CASE WHEN records < 500 THEN 1 END) as needs_backfill, \
			COUNT(CASE WHEN records >= 500 AND records < 2000 THEN 1 END) as partial_data, \
			COUNT(CASE WHEN records >= 2000 THEN 1 END) as complete \
		FROM (SELECT stock_code, COUNT(*) as records FROM stock_prices GROUP BY stock_code) sub;"

# Daily sync commands
daily-sync-local: ## Run daily sync locally (updates shorts + stock prices)
	@echo "üîÑ Running daily sync locally..."
	@if [ -z "$$DATABASE_URL" ]; then \
		export DATABASE_URL="postgresql://admin:password@localhost:5438/shorts"; \
	fi; \
	cd services/daily-sync && python3 comprehensive_daily_sync.py

daily-sync-deploy: ## Deploy daily sync job to Cloud Run (scheduled for 2 AM AEST)
	@echo "‚òÅÔ∏è  Deploying daily sync to Cloud Run..."
	@if [ -z "$$DATABASE_URL" ]; then \
		echo "‚ùå DATABASE_URL environment variable is required"; \
		echo "   Usage: export DATABASE_URL='postgresql://...'"; \
		exit 1; \
	fi
	@cd services/daily-sync && chmod +x deploy.sh && ./deploy.sh

daily-sync-execute: ## Execute daily sync job now (Cloud Run)
	@echo "üöÄ Executing daily sync job..."
	@gcloud run jobs execute comprehensive-daily-sync \
		--region asia-northeast1 \
		--project shorted-dev-aba5688f

daily-sync-logs: ## View daily sync job logs
	@echo "üìã Viewing daily sync logs..."
	@gcloud logging read \
		"resource.type=cloud_run_job AND resource.labels.job_name=comprehensive-daily-sync" \
		--limit 100 \
		--project shorted-dev-aba5688f \
		--format="table(timestamp, severity, textPayload)"

daily-sync-status: ## Check daily sync scheduler status
	@echo "‚è∞ Checking scheduler status..."
	@gcloud scheduler jobs describe comprehensive-daily-sync-trigger \
		--location asia-northeast1 \
		--project shorted-dev-aba5688f

daily-sync-test: ## Run e2e tests for daily sync
	@echo "üß™ Running daily sync integration tests..."
	@cd services/daily-sync && ./test_integration.sh

daily-sync-test-quick: ## Run quick tests (no external API calls)
	@echo "üß™ Running quick tests..."
	@cd services/daily-sync && python3 -m pytest test_daily_sync.py::TestDatabaseConnectivity -v

demo-stock-data: ## Demo: Test stock data fetching with progress bar (no database required)
	@echo "üìä Running stock data fetching demo..."
	@cd services/stock-price-ingestion && source venv/bin/activate && python demo_populate.py

demo-stock-data-custom: ## Demo: Test custom stocks and date range
	@echo "üìä Usage: make demo-stock-data-custom STOCKS=CBA,BHP,CSL START=2025-07-01"
	@cd services/stock-price-ingestion && source venv/bin/activate && python demo_populate.py --stocks $(STOCKS) --start-date $(START)

# Linting commands
lint: lint-frontend lint-backend

lint-frontend:
	@echo "üîç Linting frontend..."
	@cd web && npm run lint -- --max-warnings 1000

lint-backend: lint-backend-install
	@echo "üîç Linting backend with golangci-lint..."
	@cd services && golangci-lint run ./...

lint-backend-install:
	@which golangci-lint > /dev/null || { \
		echo "üì¶ Installing golangci-lint..."; \
		if [ "$$(uname)" = "Darwin" ]; then \
			brew install golangci-lint; \
		else \
			curl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s -- -b $$(go env GOPATH)/bin v1.61.0; \
		fi; \
	}

lint-backend-quick:
	@echo "üîç Quick linting backend (go vet + go fmt)..."
	@cd services && go vet ./... && go fmt ./...

# Format commands
format: format-frontend format-backend

format-frontend:
	@echo "‚ú® Formatting frontend code..."
	@cd web && npx prettier --write .

format-backend:
	@echo "‚ú® Formatting backend code..."
	@cd services && go fmt ./...

# CI/CD helpful commands
ci-test: install test-coverage lint
	@echo "‚úÖ CI tests completed successfully"

pre-commit: test
	@echo "‚úÖ Pre-commit checks passed - ready to push!"

pre-push: test
	@echo "‚úÖ Pre-push validation complete - all tests passed!"

# Service-specific shortcuts
test-shorts:
	@echo "üß™ Running shorts service tests..."
	@cd services && make test.shorts

# Validation commands
test-validation: test-backend-validation test-data-validation
	@echo "‚úÖ All validation tests completed"

test-backend-validation:
	@echo "üß™ Running backend validation tests..."
	@cd services && go test -v ./shorts/internal/services/shorts -run TestValidate
	@cd services && go test -v ./market-data -run TestValidate

test-data-validation:
	@echo "üß™ Running data validation tests..."
	@cd services/stock-price-ingestion && python -m pytest test_data_validation.py -v

# Integration testing commands
test-integration-local:
	@echo "üß™ Running integration tests with local backend..."
	@cd services && make test-integration-local

test-integration: test-stack-up
	@echo "üß™ Running full-stack integration tests..."
	@sleep 15  # Give services time to start and be ready
	@cd test/integration && go mod download && go test -v ./...
	@make test-stack-down

test-e2e: test-stack-up
	@echo "üé≠ Running Playwright E2E tests..."
	@sleep 15  # Give services time to start
	@cd web && npm run test:e2e
	@make test-stack-down

test-e2e-ui: test-stack-up
	@echo "üé≠ Running Playwright E2E tests with UI..."
	@sleep 15
	@cd web && npm run test:e2e:ui
	@make test-stack-down

test-all-integration: test-integration test-e2e
	@echo "‚úÖ All integration tests completed"

test-stack-up:
	@echo "üöÄ Starting test environment..."
	@cd test/integration && docker compose -f docker-compose.test.yml up -d
	@echo "‚è≥ Waiting for services to be ready..."
	@echo "Waiting for database to be ready..."
	@timeout 60 bash -c 'until docker exec $$(docker compose -f test/integration/docker-compose.test.yml ps -q postgres-test) pg_isready -U test_user; do sleep 2; done' || echo "Database may not be ready"
	@echo "Waiting for backend service to be ready..."
	@echo "Waiting for backend service to be ready..."
	@BACKEND_PORT=$$(docker port $$(docker compose -f test/integration/docker-compose.test.yml ps -q shorts-service-test) 8080/tcp 2>/dev/null | cut -d: -f2); \
		if [ -n "$$BACKEND_PORT" ]; then \
			timeout 60 bash -c "until curl -f http://localhost:$$BACKEND_PORT/health > /dev/null 2>&1; do sleep 2; done" || echo "Backend may not be ready"; \
		fi
	@echo "Waiting for frontend service to be ready..."
	@FRONTEND_PORT=$$(docker port $$(docker compose -f test/integration/docker-compose.test.yml ps -q web-test) 3000/tcp 2>/dev/null | cut -d: -f2); \
		if [ -n "$$FRONTEND_PORT" ]; then \
			timeout 60 bash -c "until curl -f http://localhost:$$FRONTEND_PORT/api/health > /dev/null 2>&1; do sleep 2; done" || echo "Frontend may not be ready"; \
		fi
	@echo "‚úÖ Test environment is ready"

test-stack-down:
	@echo "üõë Stopping test environment..."
	@cd test/integration && docker compose -f docker-compose.test.yml down -v
	@echo "üßπ Cleaning up test containers..."
	@docker system prune -f --filter "label=com.docker.compose.project=integration"

test-stack-logs:
	@echo "üìã Showing test environment logs..."
	@cd test/integration && docker compose -f docker-compose.test.yml logs

test-stack-status:
	@echo "üìä Test environment status..."
	@cd test/integration && docker compose -f docker-compose.test.yml ps

# Quick development setup
setup: install
	@echo "üéâ Project setup completed!"
	@echo ""
	@echo "To get started:"
	@echo "  make dev           # Start both frontend and backend"
	@echo "  make dev-frontend  # Start frontend dev server only"
	@echo "  make dev-backend   # Start backend dev server only"
	@echo "  make test          # Run all tests"

# Database and infrastructure
db-reset:
	@echo "üóÑÔ∏è  Resetting database..."
	@echo "Note: This should connect to your database reset script"
	# Add your database reset commands here

db-diagnose: ## Diagnose database query performance issues
	@echo "üîç Diagnosing database performance..."
	@python3 scripts/diagnose-slow-queries.py

db-optimize: ## Apply performance indexes to database
	@echo "‚ö° Applying performance indexes..."
	@python3 scripts/apply-performance-indexes.py
	@echo "‚úÖ Performance indexes applied successfully"
	@echo "Run 'make db-diagnose' to verify improvements"

db-analyze: ## Update database statistics for query planner
	@echo "üìä Updating database statistics..."
	@echo "This requires DATABASE_URL environment variable to be set"
	@echo "Run: ANALYZE shorts; ANALYZE \"company-metadata\";"

db-optimize-full: ## Full database optimization (indexes + statistics + validation)
	@echo "üöÄ Running full database optimization..."
	@echo "üì¶ Checking Python dependencies..."
	@python3 -c "import asyncpg" 2>/dev/null || { \
		echo "‚ö†Ô∏è  asyncpg not found. Installing..."; \
		pip install -q asyncpg || { \
			echo "‚ùå Failed to install asyncpg. Please run: pip install asyncpg"; \
			exit 1; \
		}; \
	}
	@if [ -z "$$DATABASE_URL" ] && [ -z "$$SUPABASE_DB_URL" ]; then \
		echo "‚ùå DATABASE_URL or SUPABASE_DB_URL environment variable is required"; \
		echo "   Example: export DATABASE_URL='postgresql://user:pass@host:port/db'"; \
		exit 1; \
	fi
	@python3 scripts/optimize-database.py

# Health checks
health-check:
	@echo "ü©∫ Running health checks..."
	@echo "Checking frontend dependencies..."
	@cd web && npm ls --depth=0 > /dev/null || echo "‚ùå Frontend dependency issues found"
	@echo "Checking backend module..."
	@cd services && go mod verify > /dev/null || echo "‚ùå Backend module issues found"
	@echo "‚úÖ Health check completed"

# Generate API docs
docs:
	@echo "üìö Generating API documentation..."
	@cd services && make generate.statik

# Show test results summary
test-summary: test-coverage
	@echo ""
	@echo "üìã Test Summary:"
	@echo "Frontend coverage: See web/coverage/index.html"
	@echo "Backend coverage: See services/coverage.html"

# =========================================
# Search Index Management (Algolia)
# =========================================

algolia-sync: ## Sync Algolia search index with local database
	@echo "üîÑ Syncing Algolia index with local database..."
	@cd web && make algolia.sync

algolia-sync-prod: ## Sync Algolia search index with production database
	@if [ -z "$$DATABASE_URL" ]; then echo "‚ùå DATABASE_URL required"; exit 1; fi
	@echo "üîÑ Syncing Algolia index with production database..."
	@cd web && DATABASE_URL=$$DATABASE_URL make algolia.sync.prod

algolia-search: ## Test Algolia search (usage: make algolia-search Q=BHP)
	@cd web && make algolia.search Q=$(Q)

# =========================================
# Company Metadata Pipeline
# =========================================

enrich-metadata: ## Enrich company metadata using GPT-4 (usage: make enrich-metadata LIMIT=10)
	@echo "üß† Enriching company metadata..."
	@cd analysis && python enrich_database.py --limit $(or $(LIMIT),10)

enrich-metadata-all: ## Enrich ALL company metadata (expensive - uses GPT-4)
	@echo "‚ö†Ô∏è  This will enrich ALL companies using GPT-4 API calls"
	@read -p "Are you sure? Type 'yes' to confirm: " confirm && [ "$$confirm" = "yes" ] || exit 1
	@cd analysis && python enrich_database.py --all

enrich-metadata-stocks: ## Enrich specific stocks (usage: make enrich-metadata-stocks STOCKS="CBA BHP")
	@if [ -z "$(STOCKS)" ]; then echo "Usage: make enrich-metadata-stocks STOCKS='CBA BHP WBC'"; exit 1; fi
	@echo "üß† Enriching metadata for: $(STOCKS)..."
	@cd analysis && python enrich_database.py --stocks $(STOCKS)

# =========================================
# Full Data Pipeline
# =========================================

pipeline-local: ## Run full pipeline locally: enrich ‚Üí sync Algolia
	@echo "üöÄ Running full data pipeline (local)..."
	@echo ""
	@echo "Step 1/2: Enriching company metadata..."
	@cd analysis && python enrich_database.py --limit $(or $(LIMIT),5) || true
	@echo ""
	@echo "Step 2/2: Syncing Algolia index..."
	@cd web && make algolia.sync
	@echo ""
	@echo "‚úÖ Pipeline complete!"

pipeline-prod: ## Run full pipeline on production: enrich ‚Üí sync Algolia
	@if [ -z "$$DATABASE_URL" ]; then echo "‚ùå DATABASE_URL required"; exit 1; fi
	@if [ -z "$$OPENAI_API_KEY" ]; then echo "‚ùå OPENAI_API_KEY required"; exit 1; fi
	@echo "üöÄ Running full data pipeline (production)..."
	@echo ""
	@echo "Step 1/2: Enriching company metadata..."
	@cd analysis && python enrich_database.py --limit $(or $(LIMIT),10)
	@echo ""
	@echo "Step 2/2: Syncing Algolia index..."
	@cd web && DATABASE_URL=$$DATABASE_URL make algolia.sync.prod
	@echo ""
	@echo "‚úÖ Pipeline complete!"

pipeline-daily: ## Run daily sync pipeline: ASIC data ‚Üí stock prices ‚Üí Algolia
	@echo "üîÑ Running daily sync pipeline..."
	@echo ""
	@echo "Step 1/2: Syncing ASIC shorts + stock prices..."
	@make daily-sync-local
	@echo ""
	@echo "Step 2/2: Syncing Algolia index..."
	@cd web && make algolia.sync
	@echo ""
	@echo "‚úÖ Daily pipeline complete!"

pipeline-help: ## Show pipeline documentation
	@echo ""
	@echo "üìä Data Pipeline Overview"
	@echo "========================="
	@echo ""
	@echo "The data pipeline has 3 main stages:"
	@echo ""
	@echo "  1. DISCOVER: Enrich company metadata"
	@echo "     - Uses GPT-4 to generate summaries"
	@echo "     - Crawls company websites for details"
	@echo "     - Fetches data from Yahoo Finance"
	@echo "     Commands: make enrich-metadata, enrich-metadata-stocks"
	@echo ""
	@echo "  2. UPDATE DB: Sync market data"
	@echo "     - Downloads ASIC short selling data"
	@echo "     - Updates stock prices from Yahoo/Alpha Vantage"
	@echo "     Commands: make daily-sync-local, populate-data"
	@echo ""
	@echo "  3. UPDATE INDEX: Sync Algolia search"
	@echo "     - Pushes company metadata to Algolia"
	@echo "     - Configures search relevance settings"
	@echo "     Commands: make algolia-sync, algolia-sync-prod"
	@echo ""
	@echo "Full Pipelines:"
	@echo "  make pipeline-local    - Run enrichment + Algolia sync locally"
	@echo "  make pipeline-prod     - Run enrichment + Algolia sync on production"
	@echo "  make pipeline-daily    - Run ASIC sync + Algolia sync (daily job)"
	@echo ""