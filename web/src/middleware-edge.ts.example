/**
 * Example Vercel Edge Middleware with Rate Limiting
 * 
 * This file shows how to implement edge-based rate limiting using Vercel KV.
 * To use this:
 * 1. Install: npm install @upstash/ratelimit @upstash/redis
 * 2. Set up Vercel KV in your Vercel dashboard
 * 3. Rename this file to middleware.ts
 * 4. Configure your KV connection in .env
 */

import { NextRequest, NextResponse } from "next/server";
import { Ratelimit } from "@upstash/ratelimit";
import { Redis } from "@upstash/redis";
import { getToken } from "next-auth/jwt";

// Initialize Redis client
// These env vars are automatically provided by Vercel when you set up KV
const redis = new Redis({
  url: process.env.KV_REST_API_URL!,
  token: process.env.KV_REST_API_TOKEN!,
});

// Create rate limiters with different policies
const anonymousLimiter = new Ratelimit({
  redis,
  // Sliding window: 20 requests per 60 seconds
  limiter: Ratelimit.slidingWindow(20, "60 s"),
  analytics: true,
  prefix: "ratelimit:anon",
});

const authenticatedLimiter = new Ratelimit({
  redis,
  // Sliding window: 200 requests per 60 seconds  
  limiter: Ratelimit.slidingWindow(200, "60 s"),
  analytics: true,
  prefix: "ratelimit:auth",
});

// Paths that require rate limiting
const RATE_LIMITED_PATHS = [
  "/api/market-data",
  "/api/search",
  "/api/shorts",
];

// Paths that are public and should have stricter limits
const PUBLIC_API_PATHS = [
  "/api/market-data/historical",
  "/api/market-data/multiple-quotes",
  "/api/search/stocks",
];

export async function middleware(request: NextRequest) {
  const { pathname } = request.nextUrl;

  // Only rate limit API routes
  const shouldRateLimit = RATE_LIMITED_PATHS.some((path) =>
    pathname.startsWith(path)
  );

  if (!shouldRateLimit) {
    return NextResponse.next();
  }

  try {
    // Check authentication
    const token = await getToken({
      req: request,
      secret: process.env.NEXTAUTH_SECRET,
    });

    // Determine identifier and rate limiter
    const isAuthenticated = !!token?.sub;
    const identifier = isAuthenticated
      ? `user:${token.sub}`
      : `ip:${request.ip || request.headers.get("x-forwarded-for") || "unknown"}`;

    // Use appropriate rate limiter
    const limiter = isAuthenticated ? authenticatedLimiter : anonymousLimiter;

    // Check rate limit
    const { success, limit, remaining, reset, pending } = await limiter.limit(
      identifier
    );

    // Wait for Redis operation to complete
    await pending;

    // Create response
    const response = success
      ? NextResponse.next()
      : NextResponse.json(
          {
            error: "Rate limit exceeded",
            message: isAuthenticated
              ? `Rate limit exceeded. Please try again in ${Math.ceil((reset - Date.now()) / 1000)} seconds.`
              : `Rate limit exceeded. Sign in for higher limits, or try again in ${Math.ceil((reset - Date.now()) / 1000)} seconds.`,
            retryAfter: Math.ceil((reset - Date.now()) / 1000),
            limit,
            authenticated: isAuthenticated,
          },
          {
            status: 429,
            headers: {
              "X-RateLimit-Limit": limit.toString(),
              "X-RateLimit-Remaining": remaining.toString(),
              "X-RateLimit-Reset": new Date(reset).toISOString(),
              "Retry-After": Math.ceil((reset - Date.now()) / 1000).toString(),
            },
          }
        );

    // Add rate limit headers to successful responses too
    if (success) {
      response.headers.set("X-RateLimit-Limit", limit.toString());
      response.headers.set("X-RateLimit-Remaining", remaining.toString());
      response.headers.set("X-RateLimit-Reset", new Date(reset).toISOString());
    }

    return response;
  } catch (error) {
    // Log error but don't block requests if rate limiting fails
    console.error("Rate limiting error:", error);
    
    // Allow request through but log the error
    // In production, you might want to track these errors
    return NextResponse.next();
  }
}

// Configure which routes use this middleware
export const config = {
  matcher: [
    /*
     * Match all API routes except:
     * - health checks
     * - auth routes (handled separately)
     * - static files
     */
    "/api/((?!health|auth).*)",
  ],
};

/*
 * Alternative: Granular Rate Limiting Per Endpoint
 * 
 * You can create different rate limiters for different endpoints:
 */

// Example: Different limits per endpoint
const endpointLimiters = {
  search: {
    anon: new Ratelimit({
      redis,
      limiter: Ratelimit.slidingWindow(50, "60 s"),
      prefix: "ratelimit:search:anon",
    }),
    auth: new Ratelimit({
      redis,
      limiter: Ratelimit.slidingWindow(500, "60 s"),
      prefix: "ratelimit:search:auth",
    }),
  },
  historical: {
    anon: new Ratelimit({
      redis,
      limiter: Ratelimit.slidingWindow(20, "60 s"),
      prefix: "ratelimit:historical:anon",
    }),
    auth: new Ratelimit({
      redis,
      limiter: Ratelimit.slidingWindow(200, "60 s"),
      prefix: "ratelimit:historical:auth",
    }),
  },
  // Add more as needed
};

// Function to get the appropriate limiter based on path
function getLimiterForPath(
  pathname: string,
  isAuthenticated: boolean
): Ratelimit {
  if (pathname.includes("/api/search")) {
    return isAuthenticated
      ? endpointLimiters.search.auth
      : endpointLimiters.search.anon;
  }
  if (pathname.includes("/api/market-data/historical")) {
    return isAuthenticated
      ? endpointLimiters.historical.auth
      : endpointLimiters.historical.anon;
  }
  // Default limiter
  return isAuthenticated ? authenticatedLimiter : anonymousLimiter;
}

/*
 * Setup Instructions:
 * 
 * 1. Install Dependencies:
 *    npm install @upstash/ratelimit @upstash/redis
 * 
 * 2. Set up Vercel KV:
 *    - Go to Vercel Dashboard → Storage → Create Database → KV
 *    - Connection details are automatically added to your project
 * 
 * 3. Environment Variables (auto-configured by Vercel):
 *    KV_REST_API_URL=your-kv-url
 *    KV_REST_API_TOKEN=your-kv-token
 *    NEXTAUTH_SECRET=your-secret
 * 
 * 4. Test locally:
 *    - Create .env.local with your KV credentials
 *    - Run: npm run dev
 *    - Test rate limits with curl or browser
 * 
 * 5. Deploy:
 *    - Push to GitHub
 *    - Vercel automatically uses KV in production
 * 
 * Cost Considerations:
 * - Vercel KV: ~$0.20 per 100k requests
 * - Free tier: 10k requests/day
 * - Pro plan: 1M requests included
 * 
 * Monitoring:
 * - Check Vercel Dashboard → Analytics → Edge Functions
 * - Monitor KV usage in Storage tab
 * - Set up alerts for high usage
 */

