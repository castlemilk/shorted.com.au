#!/usr/bin/env python3
"""
Cloud Run Service for Stock Price Data Ingestion
Provides HTTP endpoints for triggering stock price synchronization
"""

import os
import json
import logging
import asyncio
from datetime import datetime, timedelta, date
from typing import Optional, Dict, Any, List
from fastapi import FastAPI, HTTPException, BackgroundTasks, Request
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
import uvicorn
from main import StockDataIngestion
import pandas as pd
import yfinance as yf

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="Stock Price Ingestion Service",
    description="Cloud Run service for syncing ASX stock prices from Yahoo Finance",
    version="1.0.0"
)

# Configuration from environment variables
DATABASE_URL = os.environ.get('DATABASE_URL', '')
PROJECT_ID = os.environ.get('GCP_PROJECT', 'shorted-dev')
ENVIRONMENT = os.environ.get('ENVIRONMENT', 'development')

# Request/Response models
class SyncRequest(BaseModel):
    """Request model for sync endpoint"""
    symbols: Optional[List[str]] = Field(
        default=None,
        description="List of stock symbols to sync (e.g., ['CBA.AX', 'BHP.AX'])"
    )
    start_date: Optional[str] = Field(
        default=None,
        description="Start date in YYYY-MM-DD format"
    )
    end_date: Optional[str] = Field(
        default=None,
        description="End date in YYYY-MM-DD format"
    )
    days_back: Optional[int] = Field(
        default=1,
        description="Number of days to sync backwards from today"
    )
    mode: Optional[str] = Field(
        default="update",
        description="Sync mode: 'update' or 'backfill'"
    )

class SyncResponse(BaseModel):
    """Response model for sync endpoint"""
    status: str
    message: str
    batch_id: Optional[str] = None
    records_processed: Optional[int] = None
    errors: Optional[List[str]] = None

# Default ASX stocks to sync
DEFAULT_ASX_STOCKS = [
    'CBA.AX', 'BHP.AX', 'CSL.AX', 'NAB.AX', 'WBC.AX',
    'ANZ.AX', 'MQG.AX', 'WES.AX', 'TLS.AX', 'WOW.AX',
    'RIO.AX', 'FMG.AX', 'TCL.AX', 'GMG.AX', 'ALL.AX',
    'RMD.AX', 'NCM.AX', 'WPL.AX', 'SHL.AX', 'APT.AX',
    'XRO.AX', 'REA.AX', 'COH.AX', 'AMC.AX', 'QBE.AX',
    'SUN.AX', 'IAG.AX', 'ORG.AX', 'APA.AX', 'TWE.AX',
    'JHX.AX', 'STO.AX', 'MPL.AX', 'SEK.AX', 'CPU.AX',
    'ALU.AX', 'AGL.AX', 'ASX.AX', 'AZJ.AX', 'BEN.AX',
    'BLD.AX', 'BXB.AX', 'CAR.AX', 'CWN.AX', 'DXS.AX',
    'EDV.AX', 'EVN.AX', 'GPT.AX', 'HVN.AX', 'ILU.AX',
    'LLC.AX', 'MIN.AX', 'MTS.AX', 'NHF.AX', 'NST.AX'
]

@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "service": "Stock Price Ingestion",
        "version": "1.0.0",
        "environment": ENVIRONMENT,
        "status": "healthy"
    }

@app.get("/health")
async def health_check():
    """Health check endpoint for Cloud Run"""
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "database": "connected" if DATABASE_URL else "not configured"
    }

@app.post("/sync", response_model=SyncResponse)
async def sync_stock_prices(
    request: SyncRequest,
    background_tasks: BackgroundTasks
):
    """
    Sync stock prices from Yahoo Finance
    
    This endpoint triggers a stock price synchronization job.
    For daily updates, typically called by Cloud Scheduler.
    """
    try:
        # Validate database configuration
        if not DATABASE_URL:
            raise HTTPException(
                status_code=500,
                detail="Database URL not configured"
            )
        
        # Determine symbols to sync
        symbols = request.symbols or DEFAULT_ASX_STOCKS
        
        # Determine date range
        if request.start_date and request.end_date:
            start_date = datetime.strptime(request.start_date, '%Y-%m-%d').date()
            end_date = datetime.strptime(request.end_date, '%Y-%m-%d').date()
        else:
            end_date = date.today()
            start_date = end_date - timedelta(days=request.days_back)
        
        logger.info(f"Starting sync: {len(symbols)} symbols from {start_date} to {end_date}")
        
        # Run sync in background
        background_tasks.add_task(
            run_sync,
            symbols=symbols,
            start_date=start_date,
            end_date=end_date,
            mode=request.mode
        )
        
        return SyncResponse(
            status="accepted",
            message=f"Sync job started for {len(symbols)} symbols",
            batch_id=None,  # Will be generated by the sync task
            records_processed=None
        )
        
    except Exception as e:
        logger.error(f"Sync failed: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/sync-all")
async def sync_all_stocks(background_tasks: BackgroundTasks):
    """
    Sync all ASX stocks (scheduled endpoint)
    This is the primary endpoint called by Cloud Scheduler
    """
    try:
        # For scheduled runs, sync yesterday's data
        end_date = date.today()
        start_date = end_date - timedelta(days=1)
        
        # Skip weekends
        if start_date.weekday() >= 5:  # Saturday = 5, Sunday = 6
            return SyncResponse(
                status="skipped",
                message="Weekend - markets closed",
                records_processed=0
            )
        
        logger.info(f"Scheduled sync starting for {start_date}")
        
        # Run sync in background
        background_tasks.add_task(
            run_sync,
            symbols=DEFAULT_ASX_STOCKS,
            start_date=start_date,
            end_date=end_date,
            mode="update"
        )
        
        return SyncResponse(
            status="accepted",
            message=f"Daily sync started for {len(DEFAULT_ASX_STOCKS)} stocks",
            records_processed=None
        )
        
    except Exception as e:
        logger.error(f"Scheduled sync failed: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

async def run_sync(
    symbols: List[str],
    start_date: date,
    end_date: date,
    mode: str = "update"
):
    """
    Run the actual sync process
    This runs asynchronously in the background
    """
    ingestion = None
    try:
        # Initialize ingestion service
        ingestion = StockDataIngestion(DATABASE_URL)
        await ingestion.init_db()
        
        # Log start
        await ingestion.log_ingestion_start(start_date, end_date, symbols)
        
        # Process symbols
        records_inserted = 0
        records_updated = 0
        errors = 0
        error_details = []
        
        for symbol in symbols:
            try:
                # Fetch data from Yahoo Finance
                df = await ingestion.fetch_stock_data(
                    symbol=symbol,
                    start_date=start_date,
                    end_date=end_date
                )
                
                if df is not None and not df.empty:
                    # Insert/update data
                    result = await ingestion.insert_stock_prices(df, symbol)
                    records_inserted += result.get('inserted', 0)
                    records_updated += result.get('updated', 0)
                    
            except Exception as e:
                errors += 1
                error_details.append({
                    'symbol': symbol,
                    'error': str(e)
                })
                logger.error(f"Failed to sync {symbol}: {e}")
        
        # Log completion
        await ingestion.log_ingestion_complete(
            records_inserted=records_inserted,
            records_updated=records_updated,
            errors=errors,
            error_details=error_details if errors > 0 else None
        )
        
        logger.info(f"Sync completed: {records_inserted} inserted, {records_updated} updated, {errors} errors")
        
    except Exception as e:
        logger.error(f"Sync process failed: {e}")
        if ingestion:
            await ingestion.log_ingestion_complete(
                records_inserted=0,
                records_updated=0,
                errors=1,
                error_details={'error': str(e)}
            )
    finally:
        if ingestion:
            await ingestion.close_db()

@app.get("/status/{batch_id}")
async def get_sync_status(batch_id: str):
    """
    Get status of a sync job by batch ID
    """
    # This would query the ingestion log table
    # For now, return a placeholder
    return {
        "batch_id": batch_id,
        "status": "completed",
        "message": "Status endpoint not fully implemented"
    }

@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """
    Global exception handler for unhandled errors
    """
    logger.error(f"Unhandled exception: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal server error",
            "message": str(exc) if ENVIRONMENT == "development" else "An error occurred"
        }
    )

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 8080))
    uvicorn.run(
        "cloud_run_service:app",
        host="0.0.0.0",
        port=port,
        log_level="info",
        access_log=True
    )