{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logo and Icon Extraction Debugging\n",
    "\n",
    "This notebook allows you to interactively test and visualize the logo processing pipeline, specifically focusing on:\n",
    "1. Background removal (`rembg`)\n",
    "2. Text detection (`EasyOCR`)\n",
    "3. Icon extraction (`MobileSAM` with positive/negative prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from rembg import remove\n",
    "import easyocr\n",
    "import torch\n",
    "from mobile_sam import sam_model_registry, SamPredictor\n",
    "import sys\n",
    "\n",
    "# Set working directory to the processor directory if needed\n",
    "# os.chdir('services/enrichment-processor')\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to a sample logo\n",
    "input_path = \"../../data/logos/DMP.png\" # Adjust as needed\n",
    "if not os.path.exists(input_path):\n",
    "    print(\"Warning: Sample image not found. Please provide a valid path.\")\n",
    "    # You can also use a URL\n",
    "    # import httpx\n",
    "    # from io import BytesIO\n",
    "    # response = httpx.get(\"URL_HERE\")\n",
    "    # img = Image.open(BytesIO(response.content))\n",
    "else:\n",
    "    img = Image.open(input_path)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Background Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'img' in locals():\n",
    "    full_logo = remove(img)\n",
    "    # Crop to content\n",
    "    bbox = full_logo.getbbox()\n",
    "    if bbox:\n",
    "        full_logo = full_logo.crop(bbox)\n",
    "    \n",
    "    plt.imshow(full_logo)\n",
    "    plt.title(\"Background Removed & Cropped\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'full_logo' in locals():\n",
    "    # Convert to BGR for OCR\n",
    "    image_rgba = np.array(full_logo)\n",
    "    image_bgr = cv2.cvtColor(image_rgba, cv2.COLOR_RGBA2BGR)\n",
    "    h, w = image_bgr.shape[:2]\n",
    "\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    results = reader.readtext(image_bgr)\n",
    "    \n",
    "    # Visualize detection\n",
    "    vis_img = image_bgr.copy()\n",
    "    text_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    text_centers = []\n",
    "    \n",
    "    for (bbox, text, prob) in results:\n",
    "        pts = np.array(bbox, np.int32)\n",
    "        cv2.polylines(vis_img, [pts], True, (0, 255, 0), 2)\n",
    "        cv2.fillPoly(text_mask, [pts], 255)\n",
    "        \n",
    "        center_x = int(np.mean(pts[:, 0]))\n",
    "        center_y = int(np.mean(pts[:, 1]))\n",
    "        text_centers.append([center_x, center_y])\n",
    "        \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(vis_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"OCR Detections\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(text_mask, cmap='gray')\n",
    "    plt.title(\"Text Mask\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Icon Extraction (SAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'full_logo' in locals():\n",
    "    # Initialize SAM\n",
    "    model_type = \"vit_t\"\n",
    "    sam_checkpoint = \"mobile_sam.pt\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    mobile_sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "    mobile_sam.to(device=device)\n",
    "    mobile_sam.eval()\n",
    "    predictor = SamPredictor(mobile_sam)\n",
    "    \n",
    "    # Prepare prompts\n",
    "    # 1. Expand text mask for safety\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    dilated_text_mask = cv2.dilate(text_mask, kernel, iterations=2)\n",
    "    \n",
    "    # 2. Find potential icon regions\n",
    "    alpha = np.array(full_logo.split()[-1])\n",
    "    content_mask = (alpha > 0).astype(np.uint8) * 255\n",
    "    non_text_content = cv2.bitwise_and(content_mask, cv2.bitwise_not(dilated_text_mask))\n",
    "    \n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(non_text_content)\n",
    "    \n",
    "    icon_points = []\n",
    "    if num_labels > 1:\n",
    "        largest_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
    "        centroid = centroids[largest_label]\n",
    "        icon_points.append([int(centroid[0]), int(centroid[1])])\n",
    "    \n",
    "    # Run SAM\n",
    "    predictor.set_image(image_bgr)\n",
    "    \n",
    "    input_points = np.array(icon_points + text_centers)\n",
    "    input_labels = np.array([1]*len(icon_points) + [0]*len(text_centers))\n",
    "    \n",
    "    masks, scores, logits = predictor.predict(\n",
    "        point_coords=input_points,\n",
    "        point_labels=input_labels,\n",
    "        multimask_output=True,\n",
    "    )\n",
    "    \n",
    "    # Visualize results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "        # Overlay points\n",
    "        plt.scatter(input_points[input_labels==1, 0], input_points[input_labels==1, 1], color='green', marker='*')\n",
    "        plt.scatter(input_points[input_labels==0, 0], input_points[input_labels==0, 1], color='red', marker='x')\n",
    "        plt.title(f\"Mask {i} (Score: {score:.2f})\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Final Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'masks' in locals():\n",
    "    # Criteria: low text overlap AND high SAM score\n",
    "    best_mask = None\n",
    "    max_score = -1.0\n",
    "    \n",
    "    for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "        mask_area = mask.sum()\n",
    "        overlap = np.logical_and(mask, text_mask).sum() / np.maximum(mask_area, 1)\n",
    "        \n",
    "        if overlap < 0.1 and score > max_score:\n",
    "            max_score = score\n",
    "            best_mask = mask\n",
    "            \n",
    "    if best_mask is None:\n",
    "        print(\"Using fallback: direct text removal\")\n",
    "        best_mask = non_text_content > 0\n",
    "        \n",
    "    # Extract and crop\n",
    "    final_np = np.array(full_logo)\n",
    "    final_np[~best_mask, 3] = 0\n",
    "    final_img = Image.fromarray(final_np)\n",
    "    bbox = final_img.getbbox()\n",
    "    if bbox:\n",
    "        final_img = final_img.crop(bbox)\n",
    "        \n",
    "    plt.imshow(final_img)\n",
    "    plt.title(\"Final Extracted Icon\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
